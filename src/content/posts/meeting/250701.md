---
title: meeting-250701
published: 2025-07-01
tags: []
category: Meeting
draft: false
---

# 논문 읽기

@CookieHCl [Transformer (Attention Is All You Need)](https://arxiv.org/abs/1706.03762)  
@Yeon-kr [경제학 지식 분석을 위한 BERT 기반 관계추출 모델과 지식그래프](https://www.kci.go.kr/kciportal/ci/sereArticleSearch/ciSereArtiView.kci?sereArticleSearchBean.artiId=ART002918452)  
@plsyua (강제로 시킴) [Word2Vec (Efficient Estimation of Word Representations in Vector Space)](https://arxiv.org/abs/1301.3781)  
@JunJin1218 [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)

# 할 일

Pre-trained Transformer 갖고와서 r-vector 어떻게 생겼는지 관찰

## Pre-trained Transformer 가져오기

걍 얘기도 안 꺼냄

널린 BERT 아무거나 가져오면 되지 않을까?

## r-vector들 저장하기

걍 SQLite로 하기?

- 토큰 id
- 토큰 string
- 토큰이 사용된 문장(의 id)
- representation vector

일단은 이정도만; 물론 graph 등을 그릴때는 더 많은 것이 필요함

## r-vector 분포 시각화

찾다가 킹갓구글을 발견함 <https://projector.tensorflow.org/>  
웹 버전 말고 [로컬버전](https://www.tensorflow.org/tensorboard/tensorboard_projector_plugin?hl=ko)도 있는 것으로 추정됨  
But tensorflow 써야함 ㅠㅠ

파일 형식은 TSV  
But TFRecord 사용해서 .bytes 이진 파일로 저장하는 경우도 있을 것 같음??  
TFRecord 사용법은 여기로 >>> <https://www.tensorflow.org/tutorials/load_data/tfrecord?hl=ko>
